{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "# google colaboratory ã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã‚’æœ‰åŠ¹ã«ã™ã‚‹\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# train_df = pd.read_csv(\"/content/drive/mydrive/signate_cup_2024_data/train.csv\")\n",
    "# test_df = pd.read_csv(\"/content/drive/mydrive/signate_cup_2024_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Age', 'TypeofContact', 'CityTier', 'DurationOfPitch',\n",
       "       'Occupation', 'Gender', 'NumberOfPersonVisiting', 'NumberOfFollowups',\n",
       "       'ProductPitched', 'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
       "       'PitchSatisfactionScore', 'Designation', 'MonthlyIncome',\n",
       "       'customer_info', 'ProdTaken'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designateion NULL count: 0\n",
      "MonthlyIncome NULL count: 56\n",
      "customer_info NULL count: 0\n"
     ]
    }
   ],
   "source": [
    "# 3ã‚«ãƒ©ãƒ ã«NULLå€¤ãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ç¢ºèª\n",
    "print(\"Designateion NULL count: {}\".format(train_df[\"Designation\"].isnull().sum()))\n",
    "print(\"MonthlyIncome NULL count: {}\".format(train_df[\"MonthlyIncome\"].isnull().sum()))\n",
    "print(\"customer_info NULL count: {}\".format(train_df[\"customer_info\"].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designationã‚«ãƒ©ãƒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fullwidth_to_halfwidth_and_extract_invalid(\n",
    "    df: pd.DataFrame,\n",
    "    column_name: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã«å¯¾ã—ã¦æ¬¡ã®å‡¦ç†ã‚’è¡Œã†:\n",
    "    1. å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›\n",
    "    2. ãã‚Œã§ã‚‚ãªãŠAã‹ã‚‰zä»¥å¤–ã®æ–‡å­—ãŒå«ã¾ã‚Œã‚‹ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        column_name (str): æ“ä½œã‚’è¡Œã†ã‚«ãƒ©ãƒ ã®åå‰\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: ä¿®æ­£å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        list: æ¡ä»¶ã«åˆã‚ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤\n",
    "    \"\"\"\n",
    "    # å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›\n",
    "    def convert_fullwidth_to_halfwidth(text: str) -> str:\n",
    "        \"\"\"\n",
    "        å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "\n",
    "        Args:\n",
    "            text (str): å…¥åŠ›æ–‡å­—åˆ—\n",
    "\n",
    "        Returns:\n",
    "            str: åŠè§’ã«å¤‰æ›ã•ã‚ŒãŸæ–‡å­—åˆ—\n",
    "        \"\"\"\n",
    "        return \"\".join(\n",
    "            chr(ord(char) - 65248) if \"ï¼¡\" <= char <= \"ï¼º\" or \"ï½\" <= char <= \"ï½š\" else char\n",
    "            for char in text\n",
    "        )\n",
    "\n",
    "    # å¯¾è±¡ã‚«ãƒ©ãƒ ã®å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›\n",
    "    df[column_name] = df[column_name].apply(lambda x: convert_fullwidth_to_halfwidth(x) if pd.notna(x) else x)\n",
    "\n",
    "    # åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«ç½®æ›\n",
    "    df[column_name] = df[column_name].str.replace(\" \", \"_\", regex=False)\n",
    "    \n",
    "    replace_dict = {\n",
    "        \"ğ™§\": \"r\",\n",
    "        \"Î±\": \"a\",\n",
    "        \"Õ\": \"S\",\n",
    "        \"Ñµ\": \"v\",\n",
    "        \"Ã—\": \"x\",\n",
    "        \"Ğµ\": \"e\",\n",
    "        \"Î‘\": \"A\",\n",
    "        \"Ğ\": \"A\",\n",
    "        \"Îœ\": \"M\",\n",
    "        \"Ğ•\": \"E\",\n",
    "        \"Ğ…\": \"S\",\n",
    "    }\n",
    "    df = df.replace(\n",
    "        {column_name: replace_dict},\n",
    "        regex=True\n",
    "    )\n",
    "    \n",
    "    # Aã‹ã‚‰zä»¥å¤–ã®æ–‡å­—ã‚’å«ã‚€è¡Œã®indexã‚’å–å¾—\n",
    "    invalid_indices = df[~df[column_name].str.match(r\"^[A-Za-z_]+$\", na=False)].index\n",
    "    \n",
    "    if len(invalid_indices) == 0:\n",
    "        df[column_name] = df[column_name].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
    "        return df, []\n",
    "\n",
    "    # æ¡ä»¶ã«åˆã‚ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—\n",
    "    unique_invalid_values = df.loc[invalid_indices, column_name].unique().tolist()\n",
    "\n",
    "    return df, unique_invalid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['executive', 'senior_manager', 'avp', 'manager', 'vp'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Designationã‚«ãƒ©ãƒ ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†\n",
    "train_df, unique_invalid_values = convert_fullwidth_to_halfwidth_and_extract_invalid(train_df, \"Designation\")\n",
    "train_df[\"Designation\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MonthlyIncomeã‚«ãƒ©ãƒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_convert_to_numeric(\n",
    "    df: pd.DataFrame, \n",
    "    column_name: str, \n",
    "    new_column_name: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã‹ã‚‰æ•°å­—ã¨ã€Œä¸‡ã€ã‚’æŠ½å‡ºã—ã€1ä¸‡å€ã—ã¦æ–°ã—ã„ã‚«ãƒ©ãƒ ã«ä¿å­˜ã™ã‚‹ã€‚\n",
    "    æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ãªã„å ´åˆã€ãã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨å€¤ã‚’è¨˜éŒ²ã™ã‚‹ã€‚\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        column_name (str): å…ƒã®ã‚«ãƒ©ãƒ å\n",
    "        new_column_name (str): çµæœã‚’ä¿å­˜ã™ã‚‹æ–°ã—ã„ã‚«ãƒ©ãƒ å\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: å‡¦ç†çµæœãŒä¿å­˜ã•ã‚ŒãŸæ–°ã—ã„ã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        list: æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ãªã‹ã£ãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®ãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    unmatched_values = []\n",
    "    \n",
    "    def convert_to_number(text: str, index: int) -> int:\n",
    "        # æ­£è¦è¡¨ç¾ã§ã€Œä¸‡ã€ã‚„æ•°å­—ã‚’å«ã‚€éƒ¨åˆ†ã‚’æŠ½å‡º\n",
    "        match = re.search(r\"(\\d+(\\.\\d+)?)(ä¸‡)?\", text)\n",
    "        if not match:\n",
    "            unmatched_values.append((index, text))\n",
    "            return None\n",
    "        # print(match)\n",
    "        number_str, _, unit = match.groups()\n",
    "        number = float(number_str)\n",
    "        if unit == \"ä¸‡\":\n",
    "            number *= 10000\n",
    "        return int(number)\n",
    "\n",
    "    # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã„ã€æ–°ã—ã„ã‚«ãƒ©ãƒ ã«ä¿å­˜\n",
    "    df[new_column_name] = [\n",
    "        convert_to_number(str(value), idx) \n",
    "        for idx, value in enumerate(df[column_name])\n",
    "    ]\n",
    "    df[new_column_name] = df[new_column_name].astype(np.float16)\n",
    "    \n",
    "    # æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ãªã‹ã£ãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’ãƒªã‚¹ãƒˆã«ã—ã¦è¿”ã™\n",
    "    unique_unmatched_values = list({value for _, value in unmatched_values})\n",
    "    \n",
    "    return df, unique_unmatched_values\n",
    "\n",
    "# # ä½¿ç”¨ä¾‹\n",
    "# data = {\n",
    "#     \"original_column\": [\"æœˆå30.0ä¸‡å††\", \"å¹´å1.5ä¸‡\", \"ãƒœãƒ¼ãƒŠã‚¹3000\", \"åŸºæœ¬çµ¦20ä¸‡\", \"ä¸æ­£ãªå€¤\", \"another invalid value\"],\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# \n",
    "# # é–¢æ•°ã®é©ç”¨\n",
    "# df, unmatched = extract_and_convert_to_numeric(df, \"original_column\", \"numeric_value\")\n",
    "# print(df)\n",
    "# print(\"Unmatched values:\", unmatched)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "train_df, unique_invalid_values = extract_and_convert_to_numeric(train_df, \"MonthlyIncome\", \"MonthlyIncomeNumeric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer_infoã‚«ãƒ©ãƒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2453540088.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[46], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise ValueError(f\"\"{text}\" is not found in the replacement dictionary.\")\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def customer_info_preprocess(\n",
    "    df: pd.DataFrame,  # å…¥åŠ›ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    column_name: str,  # å‡¦ç†å¯¾è±¡ã®ã‚«ãƒ©ãƒ å\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®æ–‡å­—åˆ—ã‚’å‡¦ç†ã—ã€\n",
    "    å„å˜èªã‚’æ¡ä»¶ã«åŸºã¥ã„ã¦æ–°ã—ã„ã‚«ãƒ©ãƒ ã«åˆ†é¡ã™ã‚‹ã€‚\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        column_name (str): å¯¾è±¡ã‚«ãƒ©ãƒ å\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: å‡¦ç†çµæœã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    \"\"\"\n",
    "    # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†\n",
    "    for index, row in df.iterrows():\n",
    "        # å¥èª­ç‚¹ã‚„ã‚³ãƒ­ãƒ³ã€æ”¹è¡Œãªã©ã‚’åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›\n",
    "        cleaned_text = re.sub(r\"[ã€ã€‚ãƒ»ï¼šï¼›,.;:?!/ï¼\\n]\", \" \", str(row[column_name]))\n",
    "        \n",
    "        # å˜èªã«åˆ†å‰²\n",
    "        words = cleaned_text.split()\n",
    "\n",
    "        # å„å˜èªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿæ–½\n",
    "        marriage_history = \" \".join([word for word in words if \"å©š\" in word or \"ç‹¬\" in word])\n",
    "        car = \" \".join([word for word in words if \"è»Š\" in word])\n",
    "        children = \" \".join([word for word in words if \"å©š\" not in word and \"ç‹¬\" not in word and \"è»Š\" not in word])\n",
    "\n",
    "        # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’è¿½åŠ \n",
    "        df.at[index, \"marriage_history\"] = marriage_history\n",
    "        df.at[index, \"car\"] = car\n",
    "        df.at[index, \"children\"] = children\n",
    "    \n",
    "    # å„ã‚«ãƒ©ãƒ ã®è¡¨è¨˜æºã‚Œã‚’ä¿®æ­£\n",
    "    def dict_replace_function(\n",
    "        text: str,\n",
    "        replace_dict: dict\n",
    "    ) -> str:\n",
    "        if text in replace_dict:\n",
    "            return str(replace_dict[text])\n",
    "        else:\n",
    "            raise ValueError(f\"\"{text}\" is not found in the replacement dictionary.\")\n",
    "\n",
    "    # car, childrenã‚«ãƒ©ãƒ ã®å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ç½®ãæ›ãˆå‡¦ç†ã‚’å®Ÿæ–½\n",
    "    # carè¾æ›¸ã®ä½œæˆ\n",
    "    car_replace_dict = {\n",
    "    \"è»Šæœªæ‰€æŒ\": 0,\n",
    "    \"è‡ªå‹•è»Šæœªæ‰€æœ‰\": 0,\n",
    "    \"è»Šä¿æœ‰ãªã—\": 0,\n",
    "    \"ä¹—ç”¨è»Šãªã—\": 0,\n",
    "    \"è‡ªå®¶ç”¨è»Šãªã—\": 0,\n",
    "    \"è»Šãªã—\": 0,\n",
    "    \"è»Šã‚ã‚Š\": 1,\n",
    "    \"è»Šæ‰€æŒ\": 1,\n",
    "    \"è‡ªå®¶ç”¨è»Šã‚ã‚Š\": 1,\n",
    "    \"è»Šä¿æœ‰\": 1,\n",
    "    \"ä¹—ç”¨è»Šæ‰€æŒ\": 1,\n",
    "    \"è‡ªå‹•è»Šæ‰€æœ‰\": 1,\n",
    "    }\n",
    "    # childrenè¾æ›¸ã®ä½œæˆ\n",
    "    children_replace_dict = {\n",
    "        \"å­ä¾›ãªã—\": 0,\n",
    "        \"å­ä¾›ç„¡ã—\": 0,\n",
    "        \"ç„¡å­\": 0,\n",
    "        \"å­ä¾›ã‚¼ãƒ­\": 0,\n",
    "        \"éè‚²å…å®¶åº­\": 0,\n",
    "        \"å­è‚²ã¦çŠ¶æ³ä¸æ˜\": np.nan,\n",
    "        \"å­ã®æ•°ä¸è©³\": np.nan,\n",
    "        \"å­ä¾›ã®æ•°ä¸æ˜\": np.nan,\n",
    "        \"ã“ã©ã‚‚1äºº\": 1,\n",
    "        \"1å…\": 1,\n",
    "        \"å­ä¾›1äºº\": 1,\n",
    "        \"å­ä¾›æœ‰ã‚Š(1äºº)\": 1,\n",
    "        \"å­ä¾›æœ‰ã‚Š 1äºº\": 1,\n",
    "        \"ã“ã©ã‚‚2äºº\": 2,\n",
    "        \"2å…\": 2,\n",
    "        \"å­ä¾›2äºº\": 2,\n",
    "        \"å­ä¾›æœ‰ã‚Š(2äºº)\": 2,\n",
    "        \"ã“ã©ã‚‚3äºº\": 3,\n",
    "        \"3å…\": 3,\n",
    "        \"å­ä¾›3äºº\": 3,\n",
    "        \"å­ä¾›æœ‰ã‚Š 2äºº\": 2,\n",
    "        \"å­ä¾›æœ‰ã‚Š 3äºº\": 3,\n",
    "        \"å­ä¾›æœ‰ã‚Š(3äºº)\": 3,\n",
    "        \"ã‚ã‹ã‚‰ãªã„\": np.nan,\n",
    "        \"ä¸æ˜\": np.nan,\n",
    "    }\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¯¾è±¡ã‚«ãƒ©ãƒ ã«é©ç”¨\n",
    "    df[\"car\"] = df[\"car\"].apply(dict_replace_function, replace_dict=car_replace_dict)\n",
    "    df[\"children\"] = df[\"children\"].apply(dict_replace_function, replace_dict=children_replace_dict)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'nan', '1', '2', '3'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "train_df = customer_info_preprocess(train_df, \"customer_info\")\n",
    "train_df.to_csv(\"../data/train_preprocessed.csv\", index=False)\n",
    "train_df[\"marriage_history\"].unique()\n",
    "# train_df[\"car\"].unique()\n",
    "train_df[\"children\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
