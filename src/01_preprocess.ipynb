{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designationカラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fullwidth_to_halfwidth_and_extract_invalid(\n",
    "    df: pd.DataFrame,\n",
    "    column_name: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    指定されたカラムに対して次の処理を行う:\n",
    "    1. 全角英字を半角英字に変換\n",
    "    2. それでもなおAからz以外の文字が含まれるユニークな値をリストとして返す\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 対象のデータフレーム\n",
    "        column_name (str): 操作を行うカラムの名前\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 修正後のデータフレーム\n",
    "        list: 条件に合わないレコードのユニークな値\n",
    "    \"\"\"\n",
    "    # 全角英字を半角英字に変換\n",
    "    def convert_fullwidth_to_halfwidth(text: str) -> str:\n",
    "        \"\"\"\n",
    "        全角英字を半角英字に変換するヘルパー関数\n",
    "\n",
    "        Args:\n",
    "            text (str): 入力文字列\n",
    "\n",
    "        Returns:\n",
    "            str: 半角に変換された文字列\n",
    "        \"\"\"\n",
    "        return \"\".join(\n",
    "            chr(ord(char) - 65248) if \"Ａ\" <= char <= \"Ｚ\" or \"ａ\" <= char <= \"ｚ\" else char\n",
    "            for char in text\n",
    "        )\n",
    "\n",
    "    # 対象カラムの全角英字を半角英字に変換\n",
    "    df[column_name] = df[column_name].apply(\n",
    "        lambda x: convert_fullwidth_to_halfwidth(x) if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "    # 半角スペースをアンダースコアに置換\n",
    "    df[column_name] = df[column_name].str.replace(\" \", \"_\", regex=False)\n",
    "    \n",
    "    replace_dict = {\n",
    "        \"𝙧\": \"r\",\n",
    "        \"α\": \"a\",\n",
    "        \"Տ\": \"S\",\n",
    "        \"ѵ\": \"v\",\n",
    "        \"×\": \"x\",\n",
    "        \"е\": \"e\",\n",
    "        \"Α\": \"A\",\n",
    "        \"А\": \"A\",\n",
    "        \"Μ\": \"M\",\n",
    "        \"Е\": \"E\",\n",
    "        \"Ѕ\": \"S\",\n",
    "    }\n",
    "    df = df.replace(\n",
    "        {column_name: replace_dict},\n",
    "        regex=True\n",
    "    )\n",
    "    \n",
    "    # Aからz以外の文字を含む行のindexを取得\n",
    "    invalid_indices = df[~df[column_name].str.match(r\"^[A-Za-z_]+$\", na=False)].index\n",
    "    \n",
    "    if len(invalid_indices) == 0:\n",
    "        # ここまでで前処理が完了していれば、カラムの値を小文字に変換して返す\n",
    "        df[column_name] = df[column_name].apply(\n",
    "            lambda x: x.lower() if pd.notna(x) else x\n",
    "        )\n",
    "        return df\n",
    "    else:\n",
    "        # 条件に合わないレコードのユニークな値をリストとして取得\n",
    "        print(\"there are invalid values in the column: {}\".format(column_name))\n",
    "        unique_invalid_values = df.loc[invalid_indices, column_name].unique().tolist()\n",
    "        return df, unique_invalid_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MonthlyIncomeカラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_convert_to_numeric(\n",
    "    df: pd.DataFrame, \n",
    "    column_name: str, \n",
    "    new_column_name: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    指定されたカラムから数字と「万」を抽出し、1万倍して新しいカラムに保存する。\n",
    "    正規表現にマッチしない場合、そのインデックスと値を記録する。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 入力データフレーム\n",
    "        column_name (str): 元のカラム名\n",
    "        new_column_name (str): 結果を保存する新しいカラム名\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 処理結果が保存された新しいカラムが追加されたデータフレーム\n",
    "        list: 正規表現にマッチしなかったユニークな値のリスト\n",
    "    \"\"\"\n",
    "    unmatched_values = []\n",
    "    \n",
    "    def convert_to_number(text: str, index: int) -> int:\n",
    "        # 正規表現で「万」と数字を含む部分を抽出\n",
    "        match = re.search(r\"(\\d+(\\.\\d+)?)(万)?\", text)\n",
    "        if not match:\n",
    "            unmatched_values.append((index, text))\n",
    "            return None\n",
    "        number_str, _, unit = match.groups()\n",
    "        number = float(number_str)\n",
    "        if unit == \"万\":\n",
    "            number *= 10000\n",
    "        return int(number)\n",
    "\n",
    "    # 各レコードに対して処理を行い、新しいカラムに保存\n",
    "    df[new_column_name] = [\n",
    "        convert_to_number(str(value), idx) \n",
    "        for idx, value in enumerate(df[column_name])\n",
    "    ]\n",
    "    df[new_column_name] = df[new_column_name].astype(np.float32)\n",
    "    \n",
    "    if len(unmatched_values) == 0:\n",
    "        return df\n",
    "    else:\n",
    "        # 正規表現にマッチしなかったユニークな値をリストにして返す\n",
    "        print(\"there are unmatched values in the column: {}\".format(column_name))\n",
    "        unique_unmatched_values = list({value for _, value in unmatched_values})\n",
    "    \n",
    "        return df, unique_unmatched_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer_infoカラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_info_preprocess(\n",
    "    df: pd.DataFrame,  # 入力のデータフレーム\n",
    "    column_name: str,  # 処理対象のカラム名\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    各レコードに対して、指定されたカラムの文字列を処理し、\n",
    "    各単語を条件に基づいて新しいカラムに分類する。\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 処理対象のデータフレーム\n",
    "        column_name (str): 対象カラム名\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: 処理結果を含むデータフレーム\n",
    "    \"\"\"\n",
    "    # 各レコードを処理\n",
    "    for index, row in df.iterrows():\n",
    "        # 句読点やコロン、改行などを半角スペースに変換\n",
    "        cleaned_text = re.sub(r\"[、。・：；,.;:?!/／\\n]\", \" \", str(row[column_name]))\n",
    "        \n",
    "        # 単語に分割\n",
    "        words = cleaned_text.split()\n",
    "\n",
    "        # 各単語に対して処理を実施\n",
    "        marriage_history = \" \".join([word for word in words if \"婚\" in word or \"独\" in word])\n",
    "        car = \" \".join([word for word in words if \"車\" in word])\n",
    "        children = \" \".join([word for word in words if \"婚\" not in word and \"独\" not in word and \"車\" not in word])\n",
    "\n",
    "        # 各レコードに新しいカラムを追加\n",
    "        df.at[index, \"marriage_history\"] = marriage_history\n",
    "        df.at[index, \"car\"] = car\n",
    "        df.at[index, \"children\"] = children\n",
    "    \n",
    "    # 各カラムの表記揺れを修正\n",
    "    def dict_replace_function(\n",
    "        text: str,\n",
    "        replace_dict: dict\n",
    "    ) -> str:\n",
    "        if text in replace_dict:\n",
    "            return str(replace_dict[text])\n",
    "        else:\n",
    "            raise ValueError(f\"'{text}' is not found in the replacement dictionary.\")\n",
    "\n",
    "    # car, childrenカラムの各レコードに対して置き換え処理を実施\n",
    "    # car辞書の作成\n",
    "    car_replace_dict = {\n",
    "    \"車未所持\": 0,\n",
    "    \"自動車未所有\": 0,\n",
    "    \"車保有なし\": 0,\n",
    "    \"乗用車なし\": 0,\n",
    "    \"自家用車なし\": 0,\n",
    "    \"車なし\": 0,\n",
    "    \"車あり\": 1,\n",
    "    \"車所持\": 1,\n",
    "    \"自家用車あり\": 1,\n",
    "    \"車保有\": 1,\n",
    "    \"乗用車所持\": 1,\n",
    "    \"自動車所有\": 1,\n",
    "    }\n",
    "    # children辞書の作成\n",
    "    children_replace_dict = {\n",
    "        \"子供なし\": 0,\n",
    "        \"子供無し\": 0,\n",
    "        \"無子\": 0,\n",
    "        \"子供ゼロ\": 0,\n",
    "        \"非育児家庭\": 0,\n",
    "        \"子育て状況不明\": np.nan,\n",
    "        \"子の数不詳\": np.nan,\n",
    "        \"子供の数不明\": np.nan,\n",
    "        \"こども1人\": 1,\n",
    "        \"1児\": 1,\n",
    "        \"子供1人\": 1,\n",
    "        \"子供有り(1人)\": 1,\n",
    "        \"子供有り 1人\": 1,\n",
    "        \"こども2人\": 2,\n",
    "        \"2児\": 2,\n",
    "        \"子供2人\": 2,\n",
    "        \"子供有り(2人)\": 2,\n",
    "        \"こども3人\": 3,\n",
    "        \"3児\": 3,\n",
    "        \"子供3人\": 3,\n",
    "        \"子供有り 2人\": 2,\n",
    "        \"子供有り 3人\": 3,\n",
    "        \"子供有り(3人)\": 3,\n",
    "        \"わからない\": np.nan,\n",
    "        \"不明\": np.nan,\n",
    "    }\n",
    "    \n",
    "    # データフレームの対象カラムに適用\n",
    "    df[\"car\"] = df[\"car\"].apply(dict_replace_function, replace_dict=car_replace_dict)\n",
    "    df[\"children\"] = df[\"children\"].apply(dict_replace_function, replace_dict=children_replace_dict)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_last_3_cols(\n",
    "    df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    データフレームに対して前処理を行う。\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 前処理を行うデータフレーム\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 前処理後のデータフレーム\n",
    "    \"\"\"\n",
    "    \n",
    "    # カラムごとの前処理\n",
    "    df, invalid_values = convert_fullwidth_to_halfwidth_and_extract_invalid(df, \"Designation\")\n",
    "    df, unmatched_values = extract_and_convert_to_numeric(df, \"MonthlyIncome\", \"MonthlyIncome_numeric\")\n",
    "    df = customer_info_preprocess(df, \"customer_info\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルファイルを読み込む\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "# google colaboratory で実行する場合は以下を有効にする\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# train_df = pd.read_csv(\"/content/drive/mydrive/signate_cup_2024_data/train.csv\")\n",
    "# test_df = pd.read_csv(\"/content/drive/mydrive/signate_cup_2024_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_for_last_3_cols(train_df)\n",
    "test_df = preprocess_for_last_3_cols(test_df)\n",
    "train_df.to_csv(\"../data/train_preprocessed.csv\", index=False)\n",
    "test_df.to_csv(\"../data/test_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要になったカラムは以下の2つ。デバッグ目的で残しているが、不要な場合は消してください。\n",
    "- MonthlyIncome\n",
    "- customer_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
