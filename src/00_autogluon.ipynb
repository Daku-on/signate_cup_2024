{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.core.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score #精度評価に使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各種定数の定義\n",
    "# 乱数シード\n",
    "RANDOM_SEED = 42\n",
    "# target となる特徴量\n",
    "TARGET_COULMN_NAME = \"ProdTaken\"\n",
    "# 削除する特徴量のリスト\n",
    "DROP_COLUMNS = []\n",
    "# one-hot encoding する特徴量のリスト\n",
    "ONE_HOT_ENCODING_COLUMNS = []\n",
    "# ベストモデルのパス\n",
    "BEST_MODEL_PATH = \"../working/best_autogluon_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価関数の定義\n",
    "ag_roc_auc_scorer = make_scorer(\n",
    "    name=\"roc_auc_score\",\n",
    "    score_func=roc_auc_score,\n",
    "    optimum=1,\n",
    "    greater_is_better=True,\n",
    "    needs_threshold=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train_df =  pd.read_csv(\"data/train.csv\")\n",
    "X_train_df = train_df.drop(columns=[TARGET_COULMN_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの読み込み\n",
    "test_df =  pd.read_csv(\"data/test.csv\")\n",
    "X_test_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../models\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:16:51 PDT 2024; root:xnu-10063.121.3~5/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.68 GB / 16.00 GB (23.0%)\n",
      "Disk Space Avail:   55.95 GB / 926.35 GB (6.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"../models\"\n",
      "Train Data Rows:    3489\n",
      "Train Data Columns: 17\n",
      "Label Column:       ProdTaken\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3772.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.68 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['NumberOfPersonVisiting', 'NumberOfFollowups', 'PreferredPropertyStar']\n",
      "\t\t('int', [])    :  4 | ['id', 'CityTier', 'Passport', 'PitchSatisfactionScore']\n",
      "\t\t('object', []) : 10 | ['Age', 'TypeofContact', 'DurationOfPitch', 'Occupation', 'Gender', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['Age', 'TypeofContact', 'DurationOfPitch', 'Occupation', 'Gender', ...]\n",
      "\t\t('float', [])     :  3 | ['NumberOfPersonVisiting', 'NumberOfFollowups', 'PreferredPropertyStar']\n",
      "\t\t('int', [])       :  3 | ['id', 'CityTier', 'PitchSatisfactionScore']\n",
      "\t\t('int', ['bool']) :  1 | ['Passport']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.21 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc_score'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 2791, Val Rows: 698\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Hyperparameter tuning model: KNeighborsUnif ...\n",
      "Warning: Exception caused KNeighborsUnif to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: KNeighborsDist ...\n",
      "Warning: Exception caused KNeighborsDist to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: LightGBMXT ...\n",
      "Warning: Exception caused LightGBMXT to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: LightGBM ...\n",
      "Warning: Exception caused LightGBM to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: RandomForestGini ...\n",
      "Warning: Exception caused RandomForestGini to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: RandomForestEntr ...\n",
      "Warning: Exception caused RandomForestEntr to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: CatBoost ...\n",
      "Warning: Exception caused CatBoost to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: ExtraTreesGini ...\n",
      "Warning: Exception caused ExtraTreesGini to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: ExtraTreesEntr ...\n",
      "Warning: Exception caused ExtraTreesEntr to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: NeuralNetFastAI ...\n",
      "2024-08-01 22:16:35,650\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Warning: Exception caused NeuralNetFastAI to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 336, in initialize\n",
      "    hyperparameter_tune_kwargs[\"scheduler\"], hyperparameter_tune_kwargs[\"scheduler\"]\n",
      "KeyError: 'scheduler'\n",
      "'scheduler'\n",
      "Hyperparameter tuning model: XGBoost ...\n",
      "Warning: Exception caused XGBoost to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 191, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'search_strategy': 'bayesopt'}\n",
      "Hyperparameter tuning model: NeuralNetTorch ...\n",
      "Warning: Exception caused NeuralNetTorch to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2236, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1494, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/Users/takako/Desktop/GitHub/signate_cup_2024/.venv/lib/python3.10/site-packages/autogluon/core/hpo/executors.py\", line 336, in initialize\n",
      "    hyperparameter_tune_kwargs[\"scheduler\"], hyperparameter_tune_kwargs[\"scheduler\"]\n",
      "KeyError: 'scheduler'\n",
      "'scheduler'\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "        label=TARGET_COULMN_NAME,\n",
    "        eval_metric=ag_roc_auc_scorer,\n",
    "        path=\"../models\",\n",
    "    ).fit(\n",
    "        train_df,\n",
    "        # TODO: how to specify the random seed?\n",
    "        # random_state=RANDOM_SEED,\n",
    "        hyperparameters='default',\n",
    "        hyperparameter_tune_kwargs={\"search_strategy\": \"bayesopt\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict_proba(X_test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
