# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®importã‚’è¡Œã„ã¾ã™
import re
import pandas as pd
import numpy as np
import unicodedata


# kkou27  æ‹…å½“åˆ†

# ã€ŒAgeã€ã«å¯¾ã™ã‚‹å‡¦ç†
unit_list = ['æ­³', 'æ‰', 'éš›', 'ä»£']
def remove_specific_chars(text):
    for char in unit_list:
        text = text.replace(char, '')
    return text


def kanji_to_number(kanji):
    # æ¼¢æ•°å­—ã‚’ã‚¢ãƒ©ãƒ“ã‚¢æ•°å­—ã«å¤‰æ›ã™ã‚‹è¾æ›¸
    kanji_to_num = {
        'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
        'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'é›¶': 0,
        'å': 10, 'ç™¾': 100, 'åƒ': 1000, 'ä¸‡': 10000,
        'å„„': 100000000, 'å…†': 1000000000000
    }
    result = 0
    tmp = 0
    base = 1
    for char in reversed(kanji):
        if char in kanji_to_num:
            num = kanji_to_num[char]
            if num >= 10:
                if tmp == 0:
                    tmp = 1
                result += tmp * num
                tmp = 0
            else:
                tmp += num * base
                base = 1
        else:
            return kanji  # æ¼¢æ•°å­—ã§ãªã‘ã‚Œã°ãã®ã¾ã¾è¿”ã™
    if tmp != 0:
        result += tmp
    return result


def Age_transform(df_train, df_test, target = 'train'):
    """
    Ageã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
    Arges:
    - df_train: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
    - df_test: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    - target: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€å‡¦ç†ã®å¯¾è±¡ã¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ±ºã‚ã‚‹parameter
    """
    df_train_temp = df_train.copy()
    df_test_temp = df_test.copy()
    # ç‰¹å®šã®æ–‡å­—ã‚’å–ã‚Šé™¤ã„ãŸæ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    df_train_temp['Age_number'] = df_train_temp['Age'].astype(str).apply(remove_specific_chars)
    # nanã‚’-1ã«ç½®ãæ›ãˆ
    df_train_temp['Age_number'] = df_train_temp['Age_number'].replace('nan', '-1')
    # å˜ä½ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    df_train_temp['Age_unit'] = df_train_temp['Age'].astype(str).apply(lambda x: ''.join([char for char in x if char in unit_list]))
    # æ¼¢æ•°å­—ã‚’æ•°å­—ã«å¤‰æ›
    df_train_temp['Age_number']  = df_train_temp['Age_number'].apply(kanji_to_number)
    # æ•°å€¤å‹ã«å¤‰æ›
    df_train_temp['Age_number'] = df_train_temp['Age_number'].astype(float)
    df_train_temp['Age_number'] = df_train_temp['Age_number'].astype(int)

    # ç‰¹å®šã®æ–‡å­—ã‚’å–ã‚Šé™¤ã„ãŸæ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    df_test_temp['Age_number'] = df_test_temp['Age'].astype(str).apply(remove_specific_chars)
    # nanã‚’-1ã«ç½®ãæ›ãˆ
    df_test_temp['Age_number'] = df_test_temp['Age_number'].replace('nan', '-1')
    # å˜ä½ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    df_test_temp['Age_unit'] = df_test_temp['Age'].astype(str).apply(lambda x: ''.join([char for char in x if char in unit_list]))
    # æ¼¢æ•°å­—ã‚’æ•°å­—ã«å¤‰æ›
    df_test_temp['Age_number']  = df_test_temp['Age_number'].apply(kanji_to_number)
    # æ•°å€¤å‹ã«å¤‰æ›
    df_test_temp['Age_number'] = df_test_temp['Age_number'].astype(float)
    df_test_temp['Age_number'] = df_test_temp['Age_number'].astype(int)

    df_all = pd.concat([df_train_temp, df_test_temp], axis=0)

    bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
    labels = ['0-9æ­³', '10-19æ­³', '20-29æ­³', '30-39æ­³', '40-49æ­³',
                '50-59æ­³', '60-69æ­³', '70-79æ­³', '80-89æ­³', '90-100æ­³']

    # å¹´ä»£ã”ã¨ã®ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ
    df_all['å¹´ä»£'] = pd.cut(df_all['Age_number'], bins=bins, labels=labels, right=False)

    median_ages = df_all.groupby('å¹´ä»£',observed=False)['Age_number'].median()
    df_median = median_ages.reset_index()
    df_median.rename(columns={'Age_number': 'median_age'}, inplace=True)

    if target == 'train':
        # å¹´ä»£ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
        df_train_temp['å¹´ä»£'] = pd.cut(df_train_temp['Age_number'], bins=bins, labels=labels, right=False)
        # ä¸­å¤®å€¤ã‚’çµåˆ
        df_train_median = pd.merge(df_train_temp, df_median, on='å¹´ä»£', how='left')
        # å˜ä½ãŒã€Œä»£ã€ã¨ãªã£ã¦ã„ã‚‹å ´åˆã¯ãã®å¹´ä»£ã®ä¸­å¤®å€¤ã‚’Age_numberã¨ã™ã‚‹
        df_train_median['Age_number'] = np.where(df_train_median['Age_unit'] == 'ä»£', df_train_median['median_age'], df_train_median['Age_number'])
        df_train_median.drop(columns=['Age','Age_unit','å¹´ä»£','median_age'], inplace=True)
        df_train_median.rename(columns={'Age_number': 'Age'}, inplace = True)
        return df_train_median
    else:
        # å¹´ä»£ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
        df_test_temp['å¹´ä»£'] = pd.cut(df_test_temp['Age_number'], bins=bins, labels=labels, right=False)
        # ä¸­å¤®å€¤ã‚’çµåˆ
        df_test_median = pd.merge(df_test_temp, df_median, on='å¹´ä»£', how='left')
        # å˜ä½ãŒã€Œä»£ã€ã¨ãªã£ã¦ã„ã‚‹å ´åˆã¯ãã®å¹´ä»£ã®ä¸­å¤®å€¤ã‚’Age_numberã¨ã™ã‚‹
        df_test_median['Age_number'] = np.where(df_test_median['Age_unit'] == 'ä»£', df_test_median['median_age'], df_test_median['Age_number'])
        df_test_median.drop(columns=['Age','Age_unit','å¹´ä»£','median_age'], inplace=True)
        df_test_median.rename(columns={'Age_number': 'Age'}, inplace = True)
        return df_test_median


#-------------------------------------------------------------------------------------------------------------------------------------------
# ã€ŒTypeofContactã€ã«å¯¾ã™ã‚‹å‡¦ç†
def TypeofContact_transform(df):
    """
    TypeofContactã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
     Arges:
      - df_train: å‰å‡¦ç†ã‚’ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
     """
    # TypeofContactã®nanã‚’unansweredã«ç½®ãæ›ãˆã‚‹
    df['TypeofContact'] = df['TypeofContact'].fillna('unknown')

    return df


#-------------------------------------------------------------------------------------------------------------------------------------------
# ã€Œ'DurationOfPitch'ã€ã«å¯¾ã™ã‚‹å‡¦ç†
def convert_to_seconds(value):
    if pd.isna(value):
        return -1
    elif 'ç§’' in value:
        return int(value.replace('ç§’', ''))
    elif 'åˆ†' in value:
        return int(value.replace('åˆ†', '')) * 60
    return -1

def DurationOfPitch_transform(df):
    """
    DurationOfPitchã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
    Arges:
     - df: å‰å‡¦ç†ã‚’ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """

    # ç§’å˜ä½ã«çµ±ä¸€ã—ã€æ•°å€¤å‹ã«å¤‰æ›
    df['DurationOfPitch'] = df['DurationOfPitch'].apply(convert_to_seconds)
    df['DurationOfPitch'] = df['DurationOfPitch'].astype(int)

    return df


#-------------------------------------------------------------------------------------------------------------------------------------------
# ã€ŒGenderã€ã«å¯¾ã™ã‚‹å‡¦ç†
def normalize_gender(value):
    # å…¨è§’ã‚’åŠè§’ã«å¤‰æ›ã—ã€å°æ–‡å­—ã«çµ±ä¸€
    value = unicodedata.normalize('NFKC', value).lower()
    # ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤
    value = value.replace(' ', '')
    return value

def Gender_transform(df):
    """
    Genderã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
    Arges:
     - df: å‰å‡¦ç†ã‚’ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    # å‰å‡¦ç†ã®é©ç”¨
    df['Gender'] = df['Gender'].apply(normalize_gender)

    return df


#-------------------------------------------------------------------------------------------------------------------------------------------
# ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
def preprocess_data(df_train,df_test,target = 'train'):
    """
    ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°
    Arges:
    - df_train: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
    - df_test: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    - target: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€å‡¦ç†ã®å¯¾è±¡ã¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ±ºã‚ã‚‹parameter

    """
    if target == 'train':
        df_processed = Age_transform(df_train,df_test,target = 'train')
    else:
        df_processed = Age_transform(df_train,df_test,target = 'test')
    df_processed = TypeofContact_transform(df_processed)
    df_processed = DurationOfPitch_transform(df_processed)
    df_processed = Gender_transform(df_processed)

    # df_trainã®ã‚«ãƒ©ãƒ ã®ä¸¦ã³ã«æƒãˆã‚‹
    # col_list = df_train.columns.tolist()
    # # col_list.remove("ProdTaken")
    # # col_list.append("ProdTaken")
    # df_processed = df_processed[col_list]

    return df_processed

# kkou27  æ‹…å½“åˆ†çµ‚äº†

# ynb0123  æ‹…å½“åˆ†
def preprocessing(df: pd.DataFrame) -> pd.DataFrame:
    """
    dfã®Genderã‹ã‚‰PitchSatisfactionScoreã¾ã§ã®å‰å‡¦ç†
    - Gender
        - åå¯„ã›
        - maleãªã‚‰0ã€femaleãªã‚‰1ã«ã™ã‚‹
        - ã‚«ãƒ©ãƒ åã‚’Gender(is_male)ã«å¤‰æ›´
    - NumberOfPersonVisiting
        - å¤‰æ›ä¸è¦
    - NumberOfFollowups
        - nanã‚’0ã«å¤‰æ›ï¼ˆ0ãŒå€¤ã¨ã—ã¦å­˜åœ¨ã—ã¦ã„ãªã„ãŸã‚ã€0ã®æ™‚ã«ã¯nanãŒå…¥ã‚‹ã¨ä»®å®šã—ã¦ã„ã‚‹ï¼‰
        - 100, 200, ..., 600ã‚’1, 2, ..., 6ã«å¤‰æ›´ï¼ˆ%ãŒã¤ã„ã¦100å€ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®šã—ã¦ã„ã‚‹ï¼‰
    - ProductPitched
        - å…¨ã¦å°æ–‡å­—ã«å¤‰æ›
        - '|'ã‚’lã«å¤‰æ›
        - ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã§ãªã„æ–‡å­—ã‚’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã«å¤‰æ›
        - å…¨è§’ã‚’åŠè§’ã«å¤‰æ›
    - PreferredPropertyStar
        - å¤‰æ›ä¸è¦
    - NumberOfTrips
        - ã€Œå¹´4å›ã€ã€Œ5ã€ã€Œ'3'ã€ãªã©ã€intã¨strãŒæ··ã–ã£ã¦ã„ã‚‹ãŸã‚ã€å…¨ã¦intã«å¤‰æ›
    - Passport
        - å¤‰æ›ä¸è¦
    - PitchSatisfactionScore
        - å¤‰æ›ä¸è¦
    
    Parameters
    ---------------
    df: pd.DataFrame
        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ or ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ or å­¦ç¿’ï¼‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    
    Returns
    ---------------
    df_preprocessed: pd.DataFrame
        å‰å‡¦ç†æ¸ˆdataframe
    """
    # --------------- æº–å‚™ ---------------

    # å…¥åŠ›ã®dataframeãŒåŠ å·¥ã•ã‚Œãªã„ã‚ˆã†ã«ã‚³ãƒ”ãƒ¼ã‚’å–ã‚‹
    df_preprocessed = df.copy()
    # å…¨è§’ã‚’åŠè§’ã«ã™ã‚‹é–¢æ•°
    def zenkaku2hankaku(text):
        return unicodedata.normalize('NFKC', text)

    # --------------- Gender ---------------

    # å…¨è§’ã‚’åŠè§’ã«
    df_preprocessed['Gender'] = df_preprocessed['Gender'].apply(zenkaku2hankaku)
    # å¤§æ–‡å­—ã‚’å°æ–‡å­—ã«
    df_preprocessed['Gender'] = df_preprocessed['Gender'].str.lower()
    # ç”·æ€§ãªã‚‰0ã€å¥³æ€§ãªã‚‰1ã¨ã™ã‚‹
    df_preprocessed['Gender'] = np.where(df_preprocessed['Gender'].str.contains('f'), 0, 1)
    # ã‚«ãƒ©ãƒ åã‚’Gender(is_male)ã«å¤‰æ›´
    df_preprocessed = df_preprocessed.rename(columns={'Gender': 'Gender(is_male)'})

    # --------------- NumberOfFollowups ---------------

    df_preprocessed['NumberOfFollowups'] = df_preprocessed['NumberOfFollowups'].replace(
        {
            np.nan: 0,
            100: 1,
            200: 2,
            300: 3,
            400: 4,
            500: 5,
            600: 6
        }
    )

    # --------------- ProductPitched ---------------

    # å¤‰ãªæ–‡å­—ã‚’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã«
    conv2alphabet_dict = {
        'Î±': 'a',
        'Î‘': 'a',
        'Ğ²': 'b',
        'Î²': 'b',
        'ğŠ¡': 'b',
        'Ï‚': 'c',
        'Ï²': 'c',
        'Ñ': 'c',
        'ğ”¡': 'd',
        'á—': 'd',
        'ê­°': 'd',
        'Îµ': 'e',
        'Ä±': 'i',
        '|': 'l',
        'Õ¸': 'n',
        'Õ¿': 's',
        'ê“¢': 's',
        'Ñ•': 's',
        'Ã—': 'x'
    }

    def conv2alphabet(text, replacements):
        t = str.maketrans(replacements)
        return text.translate(t)
    df_preprocessed['ProductPitched'] = df_preprocessed['ProductPitched'].apply(
        lambda x: conv2alphabet(x, conv2alphabet_dict)
    )
    # å…¨è§’ã‚’åŠè§’ã«
    df_preprocessed['ProductPitched'] = df_preprocessed['ProductPitched'].apply(zenkaku2hankaku)
    # å¤§æ–‡å­—ã‚’å°æ–‡å­—ã«
    df_preprocessed['ProductPitched'] = df_preprocessed['ProductPitched'].str.lower()
    # ãªãœã‹å¤‰æ›ã§ããªã„ã‚‚ã®ãŸã¡ã‚’ãƒ‘ãƒ¯ãƒ¼ã§å¤‰æ›
    conv_dict = {
        'Ğ²asic': 'basic',
        'Ñ•uper deluxe': 'super deluxe',
        'baÕ¿ic': 'basic',
        'ê­°eluxe': 'deluxe',
        'Î²asic': 'basic',
        'Õ¿uper deluxe': 'super deluxe',
        'Õ¿tandard': 'standard',
        'standarê­°': 'standard',
        'basiÑ': 'basic',
        'dÎµluxÎµ': 'deluxe',
        'basÎ¹c': 'basic',
        'super ê­°eluxe': 'super deluxe',
        'deluxÎµ': 'deluxe',
        'Ñ•tandard': 'standard',
        'super dÎµluxe': 'super deluxe',
        'Î²asiÑ': 'basic',
        'supÎµr ê­°eluxe': 'super deluxe',
        'basÎ¹Ñ': 'basic',
        'baÑ•ic': 'basic'
    }
    df_preprocessed['ProductPitched'] = df_preprocessed['ProductPitched'].replace(conv_dict)

    # --------------- NumberOfTrips ---------------

    # æ—¥æœ¬èªã‚’intã«
    conv2ntrips = {
        'å¹´ã«1å›': 1,
        'å¹´ã«2å›': 2,
        'å¹´ã«3å›': 3,
        'å¹´ã«4å›': 4,
        'å¹´ã«5å›': 5,
        'å¹´ã«6å›': 6,
        'å¹´ã«7å›': 7,
        'å¹´ã«8å›': 8,
        'åŠå¹´ã«1å›': 2,
        'å››åŠæœŸã«1å›': 4
    }
    df_preprocessed['NumberOfTrips'] = df_preprocessed['NumberOfTrips'].replace(conv2ntrips)
    # nanã‚’intã«
    df_preprocessed['NumberOfTrips'] = df_preprocessed['NumberOfTrips'].replace({np.nan: 0})
    # strã‚’intã«
    df_preprocessed['NumberOfTrips'] = df_preprocessed['NumberOfTrips'].astype(int)

    return df_preprocessed

# ynb0123  æ‹…å½“åˆ†çµ‚äº†

# Daku-on  æ‹…å½“åˆ†


def convert_fullwidth_to_halfwidth_and_extract_invalid(
    df: pd.DataFrame,
    column_name: str,
) -> pd.DataFrame:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã«å¯¾ã—ã¦æ¬¡ã®å‡¦ç†ã‚’è¡Œã†:
    1. å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›
    2. ãã‚Œã§ã‚‚ãªãŠAã‹ã‚‰zä»¥å¤–ã®æ–‡å­—ãŒå«ã¾ã‚Œã‚‹ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™

    Args:
        df (pd.DataFrame): å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        column_name (str): æ“ä½œã‚’è¡Œã†ã‚«ãƒ©ãƒ ã®åå‰

    Returns:
        pd.DataFrame: ä¿®æ­£å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        list: æ¡ä»¶ã«åˆã‚ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤
    """
    # å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›
    def convert_fullwidth_to_halfwidth(text: str) -> str:
        """
        å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°

        Args:
            text (str): å…¥åŠ›æ–‡å­—åˆ—

        Returns:
            str: åŠè§’ã«å¤‰æ›ã•ã‚ŒãŸæ–‡å­—åˆ—
        """
        return "".join(
            chr(ord(char) - 65248) if "ï¼¡" <= char <= "ï¼º" or "ï½" <= char <= "ï½š" else char
            for char in text
        )

    # å¯¾è±¡ã‚«ãƒ©ãƒ ã®å…¨è§’è‹±å­—ã‚’åŠè§’è‹±å­—ã«å¤‰æ›
    df[column_name] = df[column_name].apply(
        lambda x: convert_fullwidth_to_halfwidth(x) if pd.notna(x) else x
    )

    # åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«ç½®æ›
    df[column_name] = df[column_name].str.replace(" ", "_", regex=False)

    replace_dict = {
        "ğ™§": "r",
        "Î±": "a",
        "Õ": "S",
        "Ñµ": "v",
        "Ã—": "x",
        "Ğµ": "e",
        "Î‘": "A",
        "Ğ": "A",
        "Îœ": "M",
        "Ğ•": "E",
        "Ğ…": "S",
    }
    df = df.replace(
        {column_name: replace_dict},
        regex=True
    )

    # Aã‹ã‚‰zä»¥å¤–ã®æ–‡å­—ã‚’å«ã‚€è¡Œã®indexã‚’å–å¾—
    invalid_indices = df[~df[column_name].str.match(r"^[A-Za-z_]+$", na=False)].index

    if len(invalid_indices) == 0:
        # ã“ã“ã¾ã§ã§å‰å‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã‚Œã°ã€ã‚«ãƒ©ãƒ ã®å€¤ã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã¦è¿”ã™
        df[column_name] = df[column_name].apply(
            lambda x: x.lower() if pd.notna(x) else x
        )
        return df, []
    else:
        # æ¡ä»¶ã«åˆã‚ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—
        print("there are invalid values in the column: {}".format(column_name))
        unique_invalid_values = df.loc[invalid_indices, column_name].unique().tolist()
        return df, unique_invalid_values


def extract_and_convert_to_numeric(
    df: pd.DataFrame,
    column_name: str,
    new_column_name: str
) -> pd.DataFrame:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã‹ã‚‰æ•°å­—ã¨ã€Œä¸‡ã€ã‚’æŠ½å‡ºã—ã€1ä¸‡å€ã—ã¦æ–°ã—ã„ã‚«ãƒ©ãƒ ã«ä¿å­˜ã™ã‚‹ã€‚
    æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ãªã„å ´åˆã€ãã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨å€¤ã‚’è¨˜éŒ²ã™ã‚‹ã€‚

    Args:
        df (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        column_name (str): å…ƒã®ã‚«ãƒ©ãƒ å
        new_column_name (str): çµæœã‚’ä¿å­˜ã™ã‚‹æ–°ã—ã„ã‚«ãƒ©ãƒ å

    Returns:
        pd.DataFrame: å‡¦ç†çµæœãŒä¿å­˜ã•ã‚ŒãŸæ–°ã—ã„ã‚«ãƒ©ãƒ ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        list: æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ãªã‹ã£ãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®ãƒªã‚¹ãƒˆ
    """
    unmatched_values = []

    def convert_to_number(
        text: object, index: int
    ) -> int:
        if text is None or pd.isna(text):
            return np.nan
        text = str(text)
        # æ­£è¦è¡¨ç¾ã§ã€Œä¸‡ã€ã¨æ•°å­—ã‚’å«ã‚€éƒ¨åˆ†ã‚’æŠ½å‡º
        match = re.search(r"(\d+(\.\d+)?)(ä¸‡)?", text)
        if not match:
            unmatched_values.append((index, text))
            return None
        number_str, _, unit = match.groups()
        number = float(number_str)
        if unit == "ä¸‡":
            number *= 10000
        return int(number)

    # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã„ã€æ–°ã—ã„ã‚«ãƒ©ãƒ ã«ä¿å­˜
    df[new_column_name] = [
        convert_to_number(value, idx) 
        for idx, value in enumerate(df[column_name])
    ]
    df[new_column_name] = df[new_column_name].astype(np.float32)

    if len(unmatched_values) == 0:
        return df, []
    else:
        # æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ãªã‹ã£ãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’ãƒªã‚¹ãƒˆã«ã—ã¦è¿”ã™
        print("there are unmatched values in the column: {}".format(column_name))
        unique_unmatched_values = list({value for _, value in unmatched_values})
        print(unique_unmatched_values)

        return df, unique_unmatched_values


def customer_info_preprocess(
    df: pd.DataFrame,  # å…¥åŠ›ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    column_name: str,  # å‡¦ç†å¯¾è±¡ã®ã‚«ãƒ©ãƒ å
) -> pd.DataFrame:
    """
    å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®æ–‡å­—åˆ—ã‚’å‡¦ç†ã—ã€
    å„å˜èªã‚’æ¡ä»¶ã«åŸºã¥ã„ã¦æ–°ã—ã„ã‚«ãƒ©ãƒ ã«åˆ†é¡ã™ã‚‹ã€‚
    Args:
        df (pd.DataFrame): å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        column_name (str): å¯¾è±¡ã‚«ãƒ©ãƒ å
    Returns:
        pd.DataFrame: å‡¦ç†çµæœã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†
    for index, row in df.iterrows():
        # å¥èª­ç‚¹ã‚„ã‚³ãƒ­ãƒ³ã€æ”¹è¡Œãªã©ã‚’åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›
        cleaned_text = re.sub(r"[ã€ã€‚ãƒ»ï¼šï¼›,.;:?!/ï¼\n]", " ", str(row[column_name]))

        # å˜èªã«åˆ†å‰²
        words = cleaned_text.split()

        # å„å˜èªã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿæ–½
        marriage_history = " ".join([word for word in words if "å©š" in word or "ç‹¬" in word])
        car = " ".join([word for word in words if "è»Š" in word])
        children = " ".join([word for word in words if "å©š" not in word and "ç‹¬" not in word and "è»Š" not in word])

        # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        df.at[index, "marriage_history"] = marriage_history
        df.at[index, "car"] = car
        df.at[index, "children"] = children

    # å„ã‚«ãƒ©ãƒ ã®è¡¨è¨˜æºã‚Œã‚’ä¿®æ­£
    def dict_replace_function(
        text: str,
        replace_dict: dict
    ) -> str:
        if text in replace_dict:
            return str(replace_dict[text])
        else:
            raise ValueError(f"'{text}' is not found in the replacement dictionary.")

    # car, childrenã‚«ãƒ©ãƒ ã®å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ç½®ãæ›ãˆå‡¦ç†ã‚’å®Ÿæ–½
    # carè¾æ›¸ã®ä½œæˆ
    car_replace_dict = {
        "è»Šæœªæ‰€æŒ": 0,
        "è‡ªå‹•è»Šæœªæ‰€æœ‰": 0,
        "è»Šä¿æœ‰ãªã—": 0,
        "ä¹—ç”¨è»Šãªã—": 0,
        "è‡ªå®¶ç”¨è»Šãªã—": 0,
        "è»Šãªã—": 0,
        "è»Šã‚ã‚Š": 1,
        "è»Šæ‰€æŒ": 1,
        "è‡ªå®¶ç”¨è»Šã‚ã‚Š": 1,
        "è»Šä¿æœ‰": 1,
        "ä¹—ç”¨è»Šæ‰€æŒ": 1,
        "è‡ªå‹•è»Šæ‰€æœ‰": 1,
    }
    # childrenè¾æ›¸ã®ä½œæˆ
    children_replace_dict = {
        "å­ä¾›ãªã—": 0,
        "å­ä¾›ç„¡ã—": 0,
        "ç„¡å­": 0,
        "å­ä¾›ã‚¼ãƒ­": 0,
        "éè‚²å…å®¶åº­": 0,
        "å­è‚²ã¦çŠ¶æ³ä¸æ˜": np.nan,
        "å­ã®æ•°ä¸è©³": np.nan,
        "å­ä¾›ã®æ•°ä¸æ˜": np.nan,
        "ã“ã©ã‚‚1äºº": 1,
        "1å…": 1,
        "å­ä¾›1äºº": 1,
        "å­ä¾›æœ‰ã‚Š(1äºº)": 1,
        "å­ä¾›æœ‰ã‚Š 1äºº": 1,
        "ã“ã©ã‚‚2äºº": 2,
        "2å…": 2,
        "å­ä¾›2äºº": 2,
        "å­ä¾›æœ‰ã‚Š(2äºº)": 2,
        "ã“ã©ã‚‚3äºº": 3,
        "3å…": 3,
        "å­ä¾›3äºº": 3,
        "å­ä¾›æœ‰ã‚Š 2äºº": 2,
        "å­ä¾›æœ‰ã‚Š 3äºº": 3,
        "å­ä¾›æœ‰ã‚Š(3äºº)": 3,
        "ã‚ã‹ã‚‰ãªã„": np.nan,
        "ä¸æ˜": np.nan,
    }

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¯¾è±¡ã‚«ãƒ©ãƒ ã«é©ç”¨
    df["car"] = df["car"].apply(dict_replace_function, replace_dict=car_replace_dict)
    df["children"] = df["children"].apply(dict_replace_function, replace_dict=children_replace_dict)

    return df


def preprocess_for_last_3_cols(
    df: pd.DataFrame,
) -> pd.DataFrame:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦å‰å‡¦ç†ã‚’è¡Œã†ã€‚

    Args:
        df (pd.DataFrame): å‰å‡¦ç†ã‚’è¡Œã†ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

    Returns:
        pd.DataFrame: å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """

    # ã‚«ãƒ©ãƒ ã”ã¨ã®å‰å‡¦ç†
    df, invalid_values = convert_fullwidth_to_halfwidth_and_extract_invalid(df, "Designation")
    df, unmatched_values = extract_and_convert_to_numeric(df, "MonthlyIncome", "MonthlyIncome_numeric")
    df = customer_info_preprocess(df, "customer_info")

    return df

# Daku-on  æ‹…å½“åˆ†çµ‚äº†


def preprocess_total(
    train_df: pd.DataFrame,
    test_df: pd.DataFrame,
) -> pd.DataFrame:
    """
    dfã®å‰å‡¦ç†
    """
    train_df = preprocess_data(
        train_df,
        test_df,
        target="train"
    )
    test_df = preprocess_data(
        train_df,
        test_df,
        target="test"
    )
    train_df = preprocessing(train_df)
    test_df = preprocessing(test_df)

    train_df = preprocess_for_last_3_cols(train_df)
    test_df = preprocess_for_last_3_cols(test_df)

    return train_df, test_df
